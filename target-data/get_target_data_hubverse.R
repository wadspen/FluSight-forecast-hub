#!/usr/bin/env Rscript
# DOC
# Generate Hubverse-formatted target data for the FluSight Forecast hub.
#
# USAGE
#     Rscript "get_target_data_hubverse.R" as_of oracle_include_after
#
# ARGUMENTS
#     as_of: Optional "YYYY-MM-DD" string.
#                    If provided, read archived target data instead of the latest version.
#     oracle_include_after: Optional "YYYY-MM-DD" string.
#                    Starting date for oracle-output target data. Defaults to "2024-11-01".
#                    Note: the modeling tasks defined in tasks.json were updated for the 2024-2025 flu
#                    season, so don't run this script with an oracle_include_after date before 2024-11-01.
#
# EXAMPLE
#     Generate Hubverse target data based on the latest available FluSight target-hospital-admissions.csv
#     `Rscript "get_target_data_hubverse.R"`
#
#     Generate Hubverse target data based on the 2025-01-11 archived version of FluSight target-hospital-admissions.csv
#     Rscript "get_target_data_hubverse.R" 2025-01-11
#
# DOC
here::i_am("target-data/get_target_data_hubverse.R")
library(cli)
suppressPackageStartupMessages(library(dplyr))
library(readr)
library(tidyr)

options(readr.show_col_types = FALSE)

#' @description
#' `get_location_data` returns supplemental information about locations used in
#' the FluSight Forecast hub.
#'
#' @return A dataframe with four columns: abbreviation (two-letter state code),
#' location (FIPS code), location_name (state name), and population.
get_location_data <- function() {
  location_file <-
    read_csv(file = "https://raw.githubusercontent.com/cdcepi/FluSight-forecast-hub/main/auxiliary-data/locations.csv") # nolint: line_length_linter.
  # first 4 columns of locations.csv are abbreviation, location, location_name, population
  location_file |> dplyr::select(1:4)
}

#' @description
#' `get_base_target_data` returns weekly target data generated by the FluSight
#' FluSight Forecast hub.
#'
#' @param target_data_path Path to the target data directory.
#' @param as_of Optional "YYYY-MM-DD" string. If provided, read archived target data instead of the latest version.
#' @return A dataframe
get_base_target_data <- function(target_data_path, as_of = NULL) {
  # if as_of is not provided, read the latest target data
  if (is.null(as_of) || is.na(as_of)) {
    get_latest <- TRUE
  } else {
    get_latest <- FALSE
  }

  if (get_latest) {
    file_name <- file.path(target_data_path, "target-hospital-admissions.csv")
  } else {
    file_name <- file.path(
      here::here(),
      "auxiliary-data",
      "target-data-archive",
      paste0("target-hospital-admissions_", as_of, ".csv"))
  }

  cli::cli_inform(paste0("Reading target data from ", file_name, "..."))

  base_target_data <- readr::read_csv(file = file_name)
  latest_date <- max(base_target_data$date, na.rm = TRUE)

  if (!get_latest && as.Date(latest_date) != as.Date(as_of)) {
    cli::cli_alert_danger(
      paste0("Latest date in the target data (", latest_date, ") does not match the 'as_of' date (", as_of, ").")
    )
    stop()
  }

  base_target_data <- cbind(
    base_target_data,
    data.frame(as_of = as.Date(latest_date))
  )

  base_target_data
}

#' @description
#' `get_existing_time_series` returns the existing Hubverse time series target data file from the FluSight Forecast hub.
#'
#' @param current_as_of "YYYY-MM-DD" string. The "as_of" date currently being processed.
#' @param column_names A vector of columns names for the time series target data.
#' @param time_series_file file.path that represents the hub's times-series target data file.
#' @return A dataframe
get_existing_time_series <- function(current_as_of, column_names, time_series_file) {

  if (file.exists(time_series_file)) {
    existing_time_series <- readr::read_csv(file = time_series_file)
  } else {
    existing_time_series <- data.frame(matrix(ncol = length(column_names), nrow = 0))
    colnames(existing_time_series) <- column_names
  }

  # if the existing time series already has entries for the as_of date we're using,
  # remove those entries (to avoid duplicates if this script is re-run)
  existing_time_series |>
    dplyr::filter(.data[["as_of"]] != as.Date(current_as_of))

}

#' @description
#' `create_time_series_target_data` creates Hubverse-formatted time series
#' target data for the "wk inc flu hosp" target.
#' "wk inc flu hosp" is the only target eligible for inclusion in the time series
#' data because it is both continuous and step-ahead.
#'
#' @param weekly_data Dataframe with weekly target data generated by the hub.
#' @param location_date Dataframe with information about each state.
#' @return A dataframe
create_time_series_target_data <- function(weekly_data, location_data) {

  weekly_data <- weekly_data |>
    dplyr::select(-location) |>
    dplyr::inner_join(location_data, by = c("location_name"))
  time_series_wk_inc <- cbind(
    data.frame(target = "wk inc flu hosp"),
    weekly_data[c("date", "location", "location_name", "value", "weekly_rate", "as_of")]
  )
  colnames(time_series_wk_inc) <- c(
    "target", "target_end_date", "location", "location_name", "observation", "weekly_rate", "as_of")

  time_series_wk_inc
}

#' @description
#' `create_oracle_output_target_data` uses Hubverse-formatted time series target data to generate
#' a corresponding set of oracle output data. If the time series target data doesn't contain
#' any records with a target_end_date greater than the specified oracle_include_after date,
#' return an empty oracle output dataframe.
#'
#' @param time_series_target Dataframe with the time series target data.
#' @param oracle_include_after "YYYY-MM-DD" string. Start date for oracle output target data.
#' @return A dataframe
create_oracle_output_target_data <- function(time_series_target, oracle_include_after) {
  oracle_output_cols <- c(
    "target", "location", "horizon", "target_end_date", "output_type", "output_type_id", "oracle_value", "as_of")

  # Filter time series rows to those that match the oracle_include_after criteria
  time_series_target <- time_series_target[time_series_target$target_end_date > oracle_include_after, ]
  if (nrow(time_series_target) == 0) {
    empty_oracle_output <- data.frame(matrix(ncol = length(oracle_output_cols), nrow = 0))
    colnames(empty_oracle_output) <- oracle_output_cols
    return(empty_oracle_output)
  }

  oracle_output_wk_inc <- create_oracle_output_wk_inc(time_series_target)
  oracle_output_rate_change <- calc_oracle_output_rate_change(time_series_target)

  oracle_output <- dplyr::bind_rows(oracle_output_wk_inc, oracle_output_rate_change)
  oracle_output <- oracle_output[oracle_output_cols]

  oracle_output
}

#' @description
#' `create_oracle_output_wk_inc` creates Hubverse-formatted oracle output
#' target data for the "wk inc flu hosp" target.
#'
#' @param time_series_target Dataframe of Hubverse-formatted time series target data.
#' @return A dataframe
create_oracle_output_wk_inc <- function(time_series_target) {
  oracle_output_wk_inc <- cbind(
    data.frame(target = "wk inc flu hosp"),
    time_series_target[c("target_end_date", "location", "observation", "as_of")]
  )
  colnames(oracle_output_wk_inc) <- c(
    "target", "target_end_date", "location", "oracle_value", "as_of")
  oracle_output_wk_inc <- oracle_output_wk_inc |>
    dplyr::cross_join(
      # add a row for each horizon defined in the modeling task
      # (except horizon -1, which is not used for scoring/viz)
      data.frame(horizon = 0:3)
    ) |>
    dplyr::mutate(
      output_type = "quantile",
    )
}

#' @description
#' `create_oracle_output_rate_change` creates Hubverse-formatted oracle output
#' target data for the "wk flu hosp rate change" target. It creates a "category"
#' column that contains the observed category for each location, date,
#' and horizon.
#'
#' Categories are "large_decrease", "decrease", "stable", "increase",
#' and "large_increase".
#'
#' @param time_series_target Dataframe of Hubverse-formatted time series target data.
#' @return A dataframe
calc_oracle_output_rate_change <- function(time_series_target) {
  obs_categories <- time_series_target |>
    dplyr::group_by(.data[["location"]]) |>
    dplyr::arrange(.data[["target_end_date"]]) |>
    dplyr::mutate(
      rate_diff0 = .data[["weekly_rate"]] - dplyr::lag(.data[["weekly_rate"]], 1),
      rate_diff1 = .data[["weekly_rate"]] - dplyr::lag(.data[["weekly_rate"]], 2),
      rate_diff2 = .data[["weekly_rate"]] - dplyr::lag(.data[["weekly_rate"]], 3),
      rate_diff3 = .data[["weekly_rate"]] - dplyr::lag(.data[["weekly_rate"]], 4),
      count_change0 = .data[["observation"]] - dplyr::lag(.data[["observation"]], 1),
      count_change1 = .data[["observation"]] - dplyr::lag(.data[["observation"]], 2),
      count_change2 = .data[["observation"]] - dplyr::lag(.data[["observation"]], 3),
      count_change3 = .data[["observation"]] - dplyr::lag(.data[["observation"]], 4)
    ) |>
    dplyr::ungroup() |>
    tidyr::pivot_longer(
      cols = c("rate_diff0", "rate_diff1", "rate_diff2", "rate_diff3"),
      names_to = "horizon",
      names_prefix = "rate_diff",
      values_to = "rate_diff",
      names_transform = list(horizon = as.integer)
    ) |>
    dplyr::mutate(
      category = dplyr::case_when(
        horizon == 0 & (abs(count_change0) < 10 | rate_diff < 0.3 & rate_diff > -0.3) ~ "stable",
        horizon == 0 & rate_diff > 1.7 ~ "large_increase",
        horizon == 0 & rate_diff < -1.7 ~ "large_decrease",
        horizon == 0 & rate_diff >= 0.3 ~ "increase",
        horizon == 0 & rate_diff <= -0.3 ~ "decrease",
        horizon == 1 & (abs(count_change1) < 10 | rate_diff < 0.5 & rate_diff > -0.5) ~ "stable",
        horizon == 1 & rate_diff > 3 ~ "large_increase",
        horizon == 1 & rate_diff < -3 ~ "large_decrease",
        horizon == 1 & rate_diff >= 0.5 ~ "increase",
        horizon == 1 & rate_diff <= -0.5 ~ "decrease",
        horizon == 2 & (abs(count_change2) < 10 | rate_diff < 0.7  & rate_diff > -0.7) ~ "stable",
        horizon == 2 & rate_diff > 4 ~ "large_increase",
        horizon == 2 & rate_diff < -4 ~ "large_decrease",
        horizon == 2 & rate_diff >= 0.7 ~ "increase",
        horizon == 2 & rate_diff <= -0.7 ~ "decrease",
        horizon == 3 & (abs(count_change3) < 10 | rate_diff < 1  & rate_diff > -1) ~ "stable",
        horizon == 3 & rate_diff > 5 ~ "large_increase",
        horizon == 3 & rate_diff < -5 ~ "large_decrease",
        horizon == 3 & rate_diff >= 1 ~ "increase",
        horizon == 3 & rate_diff <= -1 ~ "decrease"
      )
    ) |>
    dplyr::select("target_end_date", "location", "horizon", "category", "as_of") |>
    dplyr::filter(!is.na(.data[["category"]]))

  # Convert to the format for oracle output, which has an oracle_value of 1 for
  # the observed category and 0 for all other categories.
  oracle_output_rate_change <- obs_categories |>
    dplyr::select("target_end_date", "location", "horizon", "as_of") |>
    dplyr::cross_join(
      data.frame(output_type_id = c("large_decrease", "decrease", "stable", "increase", "large_increase"))
    ) |>
    dplyr::left_join(
      obs_categories |> dplyr::mutate(oracle_value = 1),
      by = c("target_end_date", "location", "horizon", "output_type_id" = "category", "as_of")
    ) |>
    dplyr::mutate(
      target = "wk flu hosp rate change",
      output_type = "pmf",
      oracle_value = ifelse(is.na(.data[["oracle_value"]]), 0, 1)
    )

  oracle_output_rate_change
}

run_target_data_tests <- function() {
  # create a vector to store test results
  ok <- (TRUE)

  # expected category is "stable":
  # - for WY (FIPS code 56), the population is small but all changes in counts are
  #   magnitude 9 or less.
  # - for US, the changes in rate are *smaller* in magnitude than
  #   +/- 0.3 at horizon 0, +/- 0.5 at horizon 1, +/- 0.7 at horizon 2, and
  #   +/- 1 at horizon 3.
  location_data <- get_location_data()
  obs_dates <- seq.Date(from = as.Date("2024-11-02"), by = "week", length.out = 10)
  us_pop <- location_data$population[location_data$location == "US"]
  us_pop_100k <- function(c) {
    floor(c * us_pop / 100000)
  }
  test_data <- data.frame(
    location = c(rep("56", 10), rep("US", 10)),
    date = rep(obs_dates, 2),
    value = c(
      c(0, 0, 0, 0, 9, 0, 0, 0, 0, 0),
      c(0, us_pop_100k(0.2999), us_pop_100k(0.4998), us_pop_100k(0.6997),
        us_pop_100k(0.9996), us_pop_100k(0.6997), us_pop_100k(0.4998),
        us_pop_100k(0.2999), 0, 0)
    )
  ) |>
    dplyr::left_join(location_data, by = "location") |>
    dplyr::mutate(
      weekly_rate = .data[["value"]] / .data[["population"]] * 100000,
      as_of = as.Date("2025-03-22")
    )

  test_ts_data <- create_time_series_target_data(test_data, location_data)

  test_oracle_output_rate_change <- calc_oracle_output_rate_change(test_ts_data)

  # all oracle values are 0 or 1
  ok <- append(ok, (all(unique(test_oracle_output_rate_change$oracle_value) %in% c(0, 1))))

  # for each date/location/horizon, oracle_value sums to 1
  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::group_by(.data[["target_end_date"]], location, .data[["horizon"]]) |>
      dplyr::summarize(sum_oracle_value = sum(.data[["oracle_value"]]), .groups = "drop") |>
      dplyr::pull("sum_oracle_value") |>
      unique() |>
      all.equal(1)
  )

  # expected categories, all stable
  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::filter(.data[["oracle_value"]] > 0) |>
      dplyr::pull("output_type_id") |>
      unique() |>
      all.equal("stable")
  )

  # expected category is "increase" or "decrease"
  # test cases are all based on US to avoid edge cases that should be assigned to
  # "stable"
  # - changes in rate are in the following ranges:
  #   - horizon 0: (-1.7, -0.3] for decrease, [0.3, 1.7) for increase
  #   - horizon 1: (-3, -0.5] for decrease, [0.5, 3) for increase
  #   - horizon 2: (-4, -0.7] for decrease, [0.7, 4) for increase
  #   - horizon 3: (-5, -1] for decrease, [1, 5) for increase
  obs_dates <- seq.Date(from = as.Date("2024-11-02"), by = "week", length.out = 12)
  test_data <- data.frame(
    location = "US",
    date = obs_dates,
    value = c(
      0, us_pop_100k(1.1), us_pop_100k(2.2), us_pop_100k(3.3),
      us_pop_100k(4.4), us_pop_100k(4.4), us_pop_100k(4.4), us_pop_100k(4.4),
      us_pop_100k(3.3), us_pop_100k(2.2), us_pop_100k(1.1), 0
    )
  ) |>
    dplyr::left_join(location_data, by = "location") |>
    dplyr::mutate(
      weekly_rate = .data[["value"]] / .data[["population"]] * 100000,
      as_of = as.Date("2025-03-22")
    )

  test_ts_data <- create_time_series_target_data(test_data, location_data)
  test_oracle_output_rate_change <- calc_oracle_output_rate_change(test_ts_data)

  # all oracle values are 0 or 1
  ok <- append(ok, all(unique(test_oracle_output_rate_change$oracle_value) %in% c(0, 1)))

  # for each date/location/horizon, oracle_value sums to 1
  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::group_by(.data[["target_end_date"]], location, .data[["horizon"]]) |>
      dplyr::summarize(sum_oracle_value = sum(.data[["oracle_value"]]), .groups = "drop") |>
      dplyr::pull("sum_oracle_value") |>
      unique() |>
      all.equal(1)
  )

  # expected categories are:
  # - NA near beginning, where there is not enough history to calculate rate change
  # - "increase" for 4 weeks
  # - "stable" for a number of weeks depending on the lookback window used for rate change
  # - "decrease" for 4 weeks
  exp_categories <- data.frame(
    target_end_date = obs_dates,
    location = "US",
    horizon_0 =
      c(rep(NA, 1), rep("increase", 4), rep("stable", 3), rep("decrease", 4)),
    horizon_1 =
      c(rep(NA, 2), rep("increase", 4), rep("stable", 2), rep("decrease", 4)),
    horizon_2 =
      c(rep(NA, 3), rep("increase", 4), rep("stable", 1), rep("decrease", 4)),
    horizon_3 =
      c(rep(NA, 4), rep("increase", 4), rep("decrease", 4))
  ) |>
    tidyr::pivot_longer(
      cols = c("horizon_0", "horizon_1", "horizon_2", "horizon_3"),
      names_to = "horizon",
      values_to = "output_type_id",
      names_prefix = "horizon_"
    ) |>
    dplyr::mutate(horizon = as.integer(.data[["horizon"]])) |>
    dplyr::filter(!is.na(.data[["output_type_id"]]))

  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::filter(.data[["oracle_value"]] > 0) |>
      dplyr::select(-"oracle_value") |>
      dplyr::full_join(exp_categories, by = c("target_end_date", "location", "horizon")) |>
      dplyr::mutate(comparison = (.data[["output_type_id.x"]] == .data[["output_type_id.y"]])) |>
      dplyr::pull("comparison") |>
      unique() |>
      all.equal(TRUE)
  )

  # expected category is "large_increase" or "large_decrease" (other categories incidentally tested)
  # test cases are all based on US to avoid edge cases that should be assigned to
  # "stable"
  # - changes in rate are in the following ranges:
  #   - horizon 0: (-infty, -1.7] for large_decrease, [1.7, infty) for large_increase
  #   - horizon 1: (-infty, -3] for large_decrease, [3, infty) for large_increase
  #   - horizon 2: (-infty, -4] for large_decrease, [4, infty) for large_increase
  #   - horizon 3: (-infty, z-5] for large_decrease, [5, infty) for large_increase
  obs_dates <- seq.Date(from = as.Date("2024-11-02"), by = "week", length.out = 12)
  test_data <- data.frame(
    location = "US",
    date = obs_dates,
    value = c(
      0, us_pop_100k(1.8), us_pop_100k(2 * 1.8), us_pop_100k(3 * 1.8),
      us_pop_100k(4 * 1.8), us_pop_100k(4 * 1.8), us_pop_100k(4 * 1.8), us_pop_100k(4 * 1.8),
      us_pop_100k(3 * 1.8), us_pop_100k(2 * 1.8), us_pop_100k(1 * 1.8), 0
    )
  ) |>
    dplyr::left_join(location_data, by = "location") |>
    dplyr::mutate(
      weekly_rate = .data[["value"]] / .data[["population"]] * 100000,
      as_of = as.Date("2025-03-22")
    )

  test_ts_data <- create_time_series_target_data(test_data, location_data)
  test_oracle_output_rate_change <- calc_oracle_output_rate_change(test_ts_data)

  # all oracle values are 0 or 1
  ok <- append(ok, all(unique(test_oracle_output_rate_change$oracle_value) %in% c(0, 1)))

  # for each date/location/horizon, oracle_value sums to 1
  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::group_by(.data[["target_end_date"]], location, .data[["horizon"]]) |>
      dplyr::summarize(sum_oracle_value = sum(.data[["oracle_value"]]), .groups = "drop") |>
      dplyr::pull("sum_oracle_value") |>
      unique() |>
      all.equal(1)
  )

  # expected categories are:
  # - NA near beginning, where there is not enough history to calculate rate change
  # - generally, a pattern of "large_increase" -> "increase" -> "stable" -> "decrease" -> "large_decrease".
  #   The exact pattern depends on the horizon/lookback window used for rate change.
  #   I figured out the right pattern by staring at the test_data.
  exp_categories <- data.frame(
    target_end_date = obs_dates,
    location = "US",
    horizon_0 = c(rep(NA, 1),
                  rep("large_increase", 4),
                  rep("stable", 3),
                  rep("large_decrease", 4)),
    horizon_1 = c(rep(NA, 2),
                  rep("large_increase", 3),
                  rep("increase", 1),
                  rep("stable", 2),
                  rep("decrease", 1),
                  rep("large_decrease", 3)),
    horizon_2 = c(rep(NA, 3),
                  rep("large_increase", 2),
                  rep("increase", 2),
                  rep("stable", 1),
                  rep("decrease", 2),
                  rep("large_decrease", 2)),
    horizon_3 = c(rep(NA, 4),
                  rep("large_increase", 2),
                  rep("increase", 2),
                  rep("decrease", 2),
                  rep("large_decrease", 2))
  ) |>
    tidyr::pivot_longer(
      cols = c("horizon_0", "horizon_1", "horizon_2", "horizon_3"),
      names_to = "horizon",
      values_to = "output_type_id",
      names_prefix = "horizon_"
    ) |>
    dplyr::mutate(horizon = as.integer(.data[["horizon"]])) |>
    dplyr::filter(!is.na(.data[["output_type_id"]]))

  ok <- append(ok,
    test_oracle_output_rate_change |>
      dplyr::filter(.data[["oracle_value"]] > 0) |>
      dplyr::select(-"oracle_value") |>
      dplyr::full_join(exp_categories, by = c("target_end_date", "location", "horizon")) |>
      dplyr::mutate(comparison = (.data[["output_type_id.x"]] == .data[["output_type_id.y"]])) |>
      dplyr::pull("comparison") |>
      unique() |>
      all.equal(TRUE)
  )
}

#' @description
#' `create_target_data` returns Hubverse formatted weekly target data generated
#' by the FluSight Forecast hub.
#'
#' @param as_of Optional "YYYY-MM-DD" string. If provided, read archived target data instead of the latest version.
#' @param oracle_include_after "YYYY-MM_DD" string. Base target data dated on or earlier will be excluded.
#' @param target_data_path Path to the target data directory.
#' @return NULL
create_target_data <- function(as_of = NULL, oracle_include_after = "2024-11-01", target_data_path) {
  # Validate input params
  tryCatch(
    as.Date(oracle_include_after, format = "%Y-%m-%d"),
    error = function(e) stop(paste0("Invalid date format for oracle_include_after. Please use 'YYYY-MM-DD': ", oracle_include_after))
  )
  if (!is.null(as_of)) {
    tryCatch(
      as.Date(as_of, format = "%Y-%m-%d"),
      error = function(e) stop(paste0("Invalid date format. Please use 'YYYY-MM-DD': ", as_of))
    )
  }

  # Where we'll save things
  time_series_file <- file.path(target_data_path, "time-series.csv")
  oracle_output_file <- file.path(target_data_path, "oracle-output.csv")

  # Get original target data from FluSight hub
  location_data <- get_location_data()
  weekly_data_all <- get_base_target_data(target_data_path = target_data_path, as_of = as_of)
  as_of <- weekly_data_all$as_of[1]

  # Specify sort order for target data files (not absolutely necessary, but helps human readibility and diffs)
  time_series_col_order <- c("as_of", "target", "target_end_date", "location", "location_name")
  oracle_col_order <- c("as_of", "target", "target_end_date", "location", "horizon", "output_type", "output_type_id")

  # create time series data and append to existing file
  time_series_target <- create_time_series_target_data(weekly_data_all, location_data)
  existing_time_series <- get_existing_time_series(as_of, colnames(time_series_target), time_series_file)
  updated_time_series <- rbind(existing_time_series, time_series_target)
  arrange_cols <- function(df, cols) {
    # Similar to `dplyr::arrange()`, but using base tools. 
    # The `do.call()` technique is a way to use the columns of a data frame
    # (or items of a list) as separate arguments to a function.
    df[do.call(order, df[cols]), ]
  }
  updated_time_series <- arrange_cols(updated_time_series, time_series_col_order)

  # Create oracle output data
  oracle_output_target <- create_oracle_output_target_data(time_series_target, oracle_include_after)
  oracle_output_target <- arrange_cols(oracle_output_target, oracle_col_order)

  # Re-order the target-data columns to reflect the files' sort order
  updated_time_series <- updated_time_series |>
    dplyr::select(all_of(time_series_col_order), everything())
  oracle_output_target <- oracle_output_target |>
    dplyr::select(all_of(oracle_col_order), everything())

 # Write updated target data files
  if (!dir.exists(target_data_path)) {
    dir.create(target_data_path, recursive = TRUE)
  }

  tryCatch({
    write.csv(updated_time_series, file = time_series_file, row.names = FALSE)
    write.csv(oracle_output_target, file = oracle_output_file, row.names = FALSE)},
    error = function(e) {
      cli::cli_alert_danger(paste0("Failed to save target data:", e$message))
      quit(save = "no", status = 1)
    }
  )
  cli::cli_alert_success("Target data saved:")
  cli::cli_bullets(c(
    "*" = time_series_file,
    "*" = oracle_output_file
  ))
}

args <- commandArgs(trailingOnly = TRUE)
as_of <- args[1]
# next line is for testing
oracle_include_after <- args[2]

# If oracle_include_after date is not provided, default to the beginning
# of the 2024-2025 flu season (note: mandatory reporting was reinstated as
# of 2024-11-01)
if (is.na(oracle_include_after) || is.null(oracle_include_after)) {
  oracle_include_after <- "2024-10-31"
}

# Run tests
ok <- run_target_data_tests()
ok <- ifelse(is.logical(ok), ok, FALSE)
if (isTRUE(all(ok))) {
  cli::cli_alert_success("All target data tests passed.")
} else {
  cli::cli_alert_danger("Target data tests failed: exiting script.")
  quit(save = "no", status = 1)
}

# Create the target data
target_data_path <- file.path(here::here(), "target-data")
create_target_data(as_of = as_of, oracle_include_after = oracle_include_after, target_data_path = target_data_path)
